{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972fe281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinsh\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n",
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9edfcaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  4.15 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  4.15 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  4.15 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  4.15 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.15 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.15 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.15 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.15 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.15 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.15 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.10 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.10 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.10 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.10 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.10 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.10 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.10 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.10 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.10 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.10 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.10 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.00 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.00 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  2.00 url/s]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:02<00:00,  1.66 file/s]\n",
      "Dl Size...: 100%|██████████| 10/10 [00:02<00:00,  4.15 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  1.66 url/s]\n",
      "                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vinsh\\Documents\\GitHub\\TF-testing\\MNIST testing.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vinsh/Documents/GitHub/TF-testing/MNIST%20testing.ipynb#ch0000001?line=0'>1</a>\u001b[0m (ds_train, ds_test), ds_info \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39;49mload(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vinsh/Documents/GitHub/TF-testing/MNIST%20testing.ipynb#ch0000001?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mmnist\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vinsh/Documents/GitHub/TF-testing/MNIST%20testing.ipynb#ch0000001?line=2'>3</a>\u001b[0m     split\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vinsh/Documents/GitHub/TF-testing/MNIST%20testing.ipynb#ch0000001?line=3'>4</a>\u001b[0m     shuffle_files\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vinsh/Documents/GitHub/TF-testing/MNIST%20testing.ipynb#ch0000001?line=4'>5</a>\u001b[0m     as_supervised\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vinsh/Documents/GitHub/TF-testing/MNIST%20testing.ipynb#ch0000001?line=5'>6</a>\u001b[0m     with_info\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vinsh/Documents/GitHub/TF-testing/MNIST%20testing.ipynb#ch0000001?line=6'>7</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vinsh/Documents/GitHub/TF-testing/MNIST%20testing.ipynb#ch0000001?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize_img\u001b[39m(image, label):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vinsh/Documents/GitHub/TF-testing/MNIST%20testing.ipynb#ch0000001?line=9'>10</a>\u001b[0m   \u001b[39m\"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_datasets\\core\\load.py:327\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[0;32m    326\u001b[0m   download_and_prepare_kwargs \u001b[39m=\u001b[39m download_and_prepare_kwargs \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m--> 327\u001b[0m   dbuilder\u001b[39m.\u001b[39mdownload_and_prepare(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdownload_and_prepare_kwargs)\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m as_dataset_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m   as_dataset_kwargs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:481\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, download_dir, download_config, file_format)\u001b[0m\n\u001b[0;32m    479\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mread_from_directory(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_dir)\n\u001b[0;32m    480\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 481\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[0;32m    482\u001b[0m       dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[0;32m    483\u001b[0m       download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m    484\u001b[0m   )\n\u001b[0;32m    486\u001b[0m   \u001b[39m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[0;32m    487\u001b[0m   \u001b[39m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[0;32m    488\u001b[0m   \u001b[39m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[0;32m    489\u001b[0m   \u001b[39m# when reading from package data.\u001b[39;00m\n\u001b[0;32m    490\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdownload_size \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39mdownloaded_size\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1218\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[0;32m   1207\u001b[0m   \u001b[39mfor\u001b[39;00m split_name, generator \u001b[39min\u001b[39;00m utils\u001b[39m.\u001b[39mtqdm(\n\u001b[0;32m   1208\u001b[0m       split_generators\u001b[39m.\u001b[39mitems(),\n\u001b[0;32m   1209\u001b[0m       desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenerating splits...\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1210\u001b[0m       unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m splits\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1211\u001b[0m       leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1212\u001b[0m   ):\n\u001b[0;32m   1213\u001b[0m     filename_template \u001b[39m=\u001b[39m naming\u001b[39m.\u001b[39mShardedFileTemplate(\n\u001b[0;32m   1214\u001b[0m         split\u001b[39m=\u001b[39msplit_name,\n\u001b[0;32m   1215\u001b[0m         dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[0;32m   1216\u001b[0m         data_dir\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_path,\n\u001b[0;32m   1217\u001b[0m         filetype_suffix\u001b[39m=\u001b[39mpath_suffix)\n\u001b[1;32m-> 1218\u001b[0m     future \u001b[39m=\u001b[39m split_builder\u001b[39m.\u001b[39;49msubmit_split_generation(\n\u001b[0;32m   1219\u001b[0m         split_name\u001b[39m=\u001b[39;49msplit_name,\n\u001b[0;32m   1220\u001b[0m         generator\u001b[39m=\u001b[39;49mgenerator,\n\u001b[0;32m   1221\u001b[0m         filename_template\u001b[39m=\u001b[39;49mfilename_template,\n\u001b[0;32m   1222\u001b[0m         disable_shuffling\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfo\u001b[39m.\u001b[39;49mdisable_shuffling,\n\u001b[0;32m   1223\u001b[0m     )\n\u001b[0;32m   1224\u001b[0m     split_info_futures\u001b[39m.\u001b[39mappend(future)\n\u001b[0;32m   1226\u001b[0m \u001b[39m# Process the result of the beam pipeline.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_datasets\\core\\split_builder.py:310\u001b[0m, in \u001b[0;36mSplitBuilder.submit_split_generation\u001b[1;34m(self, split_name, generator, filename_template, disable_shuffling)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39m# Depending on the type of generator, we use the corresponding\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m# `_build_from_xyz` method.\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(generator, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mIterable):\n\u001b[1;32m--> 310\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_from_generator(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbuild_kwargs)\n\u001b[0;32m    311\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Otherwise, beam required\u001b[39;00m\n\u001b[0;32m    312\u001b[0m   unknown_generator_type \u001b[39m=\u001b[39m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInvalid split generator value for split `\u001b[39m\u001b[39m{\u001b[39;00msplit_name\u001b[39m}\u001b[39;00m\u001b[39m`. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    314\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mExpected generator or apache_beam object. Got: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    315\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(generator)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_datasets\\core\\split_builder.py:379\u001b[0m, in \u001b[0;36mSplitBuilder._build_from_generator\u001b[1;34m(self, split_name, generator, filename_template, disable_shuffling)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[39mfor\u001b[39;00m key, example \u001b[39min\u001b[39;00m utils\u001b[39m.\u001b[39mtqdm(\n\u001b[0;32m    372\u001b[0m     generator,\n\u001b[0;32m    373\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGenerating \u001b[39m\u001b[39m{\u001b[39;00msplit_name\u001b[39m}\u001b[39;00m\u001b[39m examples...\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m     leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    377\u001b[0m ):\n\u001b[0;32m    378\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     example \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_features\u001b[39m.\u001b[39;49mencode_example(example)\n\u001b[0;32m    380\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    381\u001b[0m     utils\u001b[39m.\u001b[39mreraise(e, prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFailed to encode example:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mexample\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_datasets\\core\\features\\features_dict.py:238\u001b[0m, in \u001b[0;36mFeaturesDict.encode_example\u001b[1;34m(self, example_dict)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[39mfor\u001b[39;00m k, (feature, example_value) \u001b[39min\u001b[39;00m utils\u001b[39m.\u001b[39mzip_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feature_dict,\n\u001b[0;32m    236\u001b[0m                                                   example_dict):\n\u001b[0;32m    237\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     example[k] \u001b[39m=\u001b[39m feature\u001b[39m.\u001b[39;49mencode_example(example_value)\n\u001b[0;32m    239\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     utils\u001b[39m.\u001b[39mreraise(\n\u001b[0;32m    241\u001b[0m         e, prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mIn <\u001b[39m\u001b[39m{\u001b[39;00mfeature\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m> with name \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_datasets\\core\\features\\image_feature.py:280\u001b[0m, in \u001b[0;36mImage.encode_example\u001b[1;34m(self, image_or_path_or_fobj)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode_example\u001b[39m(\u001b[39mself\u001b[39m, image_or_path_or_fobj):\n\u001b[0;32m    279\u001b[0m   \u001b[39m\"\"\"Convert the given image into a dict convertible to tf example.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_image_encoder\u001b[39m.\u001b[39;49mencode_image_or_path(image_or_path_or_fobj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_datasets\\core\\features\\image_feature.py:77\u001b[0m, in \u001b[0;36m_ImageEncoder.encode_image_or_path\u001b[1;34m(self, image_or_path_or_fobj)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39m\"\"\"Convert the given image into a dict convertible to tf example.\"\"\"\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(image_or_path_or_fobj, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m---> 77\u001b[0m   encoded_image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_encode_image(image_or_path_or_fobj)\n\u001b[0;32m     78\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(image_or_path_or_fobj, epath\u001b[39m.\u001b[39mPathLikeCls):\n\u001b[0;32m     79\u001b[0m   image_or_path_or_fobj \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(image_or_path_or_fobj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_datasets\\core\\features\\image_feature.py:103\u001b[0m, in \u001b[0;36m_ImageEncoder._encode_image\u001b[1;34m(self, np_image)\u001b[0m\n\u001b[0;32m     91\u001b[0m _validate_np_array(\n\u001b[0;32m     92\u001b[0m     np_image,\n\u001b[0;32m     93\u001b[0m     shape\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape,\n\u001b[0;32m     94\u001b[0m     dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype,\n\u001b[0;32m     95\u001b[0m     numpy_dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy_dtype)\n\u001b[0;32m     97\u001b[0m \u001b[39m# When encoding isn't defined, default to PNG.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m# Should we be more strict about explicitly define the encoding (raise\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39m# error / warning instead) ?\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[39m# It has created subtle issues for imagenet_corrupted: images are read as\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39m# JPEG images to apply some processing, but final image saved as PNG\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[39m# (default) rather than JPEG.\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_runner\u001b[39m.\u001b[39;49mrun(_ENCODE_FN[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding_format \u001b[39mor\u001b[39;49;00m \u001b[39m'\u001b[39;49m\u001b[39mpng\u001b[39;49m\u001b[39m'\u001b[39;49m], np_image)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow_datasets\\core\\utils\\tf_utils.py:80\u001b[0m, in \u001b[0;36mTFGraphRunner.run\u001b[1;34m(self, fct, input_)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39m# TF 2.0\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m---> 80\u001b[0m   \u001b[39mreturn\u001b[39;00m fct(input_)\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     81\u001b[0m \u001b[39m# TF 1.0\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m   \u001b[39m# Should compile the function if this is the first time encountered\u001b[39;00m\n\u001b[0;32m     84\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(input_, np\u001b[39m.\u001b[39mndarray):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:3226\u001b[0m, in \u001b[0;36mencode_png\u001b[1;34m(image, compression, name)\u001b[0m\n\u001b[0;32m   3200\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mio.encode_png\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mimage.encode_png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   3201\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   3202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode_png\u001b[39m(image, compression\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   3203\u001b[0m   \u001b[39mr\u001b[39m\u001b[39m\"\"\"PNG-encode an image.\u001b[39;00m\n\u001b[0;32m   3204\u001b[0m \n\u001b[0;32m   3205\u001b[0m \u001b[39m  `image` is a 3-D uint8 or uint16 Tensor of shape `[height, width, channels]`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3224\u001b[0m \u001b[39m    A `Tensor` of type `string`.\u001b[39;00m\n\u001b[0;32m   3225\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3226\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_image_ops\u001b[39m.\u001b[39;49mencode_png(\n\u001b[0;32m   3227\u001b[0m       ops\u001b[39m.\u001b[39;49mconvert_to_tensor(image), compression, name)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_image_ops.py:1744\u001b[0m, in \u001b[0;36mencode_png\u001b[1;34m(image, compression, name)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   1743\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1744\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   1745\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mEncodePng\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, image, \u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, compression)\n\u001b[0;32m   1746\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   1747\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "batch_size = 128\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.batch(batch_size)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=12,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('tf2.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "65a2cc118529083a84dc6739be199b55c8d1d06b7b7230fc4e28211d95a663ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
